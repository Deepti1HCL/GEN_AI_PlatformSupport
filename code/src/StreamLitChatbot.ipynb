import streamlit as st
import google.generativeai as genai
import requests
from requests.auth import HTTPBasicAuth
from jira import JIRA

# Configure API key
GOOGLE_API_KEY = "AIzaSyDoQTL1oduz4fmZRuuowQnPrc7gjofDvNY"  # Replace with your actual API key
JIRA_BASE_URL = "https://deeptibbdit.atlassian.net"  # Replace with your Jira domain
JIRA_EMAIL = "deepti.bbdit@gmail.com"  # Replace with your Jira account email
JIRA_API_TOKEN = "ATATT3xFfGF0aKDg9cybvB4bSz5Dr6-_1hMhEPHf213h6BXSo552cZjIfRbf0PF3L5Ht8K08YKL2pWkK-6uP_FFpGim8hYezGvx6fv3zN4rbfc7HLpM1TP8lzDiZWKN0dZngfntrEA9mUys1cxFAEghEo_vgWyDf7yqWvHGkrL4S3iw1NpThcz8=6CC835B0"  # Replace with your Jira API token
genai.configure(api_key=GOOGLE_API_KEY)

genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

# Streamlit UI
st.set_page_config(page_title="AI Chatbot with Jira", layout="centered")
st.title("ðŸ¤– Gemini AI Chatbot + Jira")
st.write("Ask me anything or request Jira issue details!")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Function to get Jira issue details
reader = JiraReader(
    email=JIRA_EMAIL, api_token=JIRA_API_TOKEN, server_url=JIRA_BASE_URL
)
documents = reader.load_data(query="project = New Project for jira integration")

# Display chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# User input
user_input = st.chat_input("Type your question...")

if user_input:
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # Check if the user is asking for a Jira issue
    if user_input.startswith("NPFJI-"):
        print(" user inpur is "+user_input)
        jira_response = get_jira_issue(user_input)
        with st.chat_message("assistant"):
            st.markdown(jira_response)
        st.session_state.messages.append({"role": "assistant", "content": jira_response})
    else:
        # Get AI response from Gemini
        with st.chat_message("assistant"):
            response = model.generate_content(user_input)
            ai_response = response.text
            st.markdown(ai_response)

        # Add AI response to chat history
        st.session_state.messages.append({"role": "assistant", "content": ai_response})
